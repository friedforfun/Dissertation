\documentclass[../Dissertation.tex]{subfiles}

\begin{document}
\section{Further work}
\emph{
\begin{itemize}
	\item Suggested improvements for methodology
	\item Next steps
\end{itemize}
}

\begin{itemize}
    \item More datasets need to be tested
    \item More models should be used
    \item Layer selection should be automated
    \item how well does this system generalise?
    \item Further investigation should look at a relationship between higher accuracy models after only pruning and how they recover vs low accuracy models after pruning
    \item Why are there so few completely ruined networks before retraining compared to after retraining?
    \item Using this data to train a reinforcement learning dnn
\end{itemize}

Further investigation to identify which untrained pruned models will respond well to retraining (particularly with one-shot pruning methods) would be valuable because retraining is expensive and one-shot pruning is (comparatively) cheap.
This could help inform researchers or users of pruning systems weather they should try and prune again or 


\section{Discussion}
\emph{
\begin{itemize}
	\item Discuss results
\end{itemize}
What were the actual latency improvements over baseline?
}

\end{document}